{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"image/images.png\" width=\"100%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>DATA ACCESS TEMPLATE FOR <br><br> Precipitation rate at ground by GEO/IR supported by LEO/MW (H60) DATA PRODUCTS</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Template](../Template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisite and data sources\n",
    "\n",
    "Here define the prerequisites for the notebooks. See the guideline for more details.\n",
    "\n",
    "The data product being used in this section is the Blended SEVIRI / LEO MW precipitation (H60) product, an H-SAF data product. For detail information on this product, it is recommended to read the attached [product manual](#Appendix-1).\n",
    "\n",
    "The methods to acces the datat products are defined in the hsaf_data_access module that needs to be imported in in the library section. The main methods to be used are\n",
    "\n",
    "* download_h60\n",
    "* extract_and_clean_data\n",
    "* points_in_polygon\n",
    "* create_netCDF_from_data\n",
    "* add_border\n",
    "* create_folders\n",
    "\n",
    "\n",
    "### Pre-requisites\n",
    "- Python environment with required libraries installed.\n",
    "- Registered account on the H-SAF website for data access.\n",
    "\n",
    "### Data Sources\n",
    "- H60 data product from the H-SAF initiative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "Define the table of contents and update whenever new content is added to the page.\n",
    "\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "\n",
    "- [Objectives](#Objectives)\n",
    "\n",
    "- [Library imports](#Library-imports)\n",
    "\n",
    "- [Access and authentication](#Data-access-and-authentication)\n",
    "\n",
    "- [Data download](#Data-download)\n",
    "\n",
    "- [Data processing](#Data-reading-and-pre\\-processing-such-as-filter\\,-area-definition-and-data-sampling)\n",
    "\n",
    "- [Data analysis](#Data-analysis/evaluation-and-plotting)\n",
    "\n",
    "- [Results visualisation](#Results-visualisation)\n",
    "\n",
    "- [Save](#Save)\n",
    "\n",
    "- [Conclusion](#Conclusion)\n",
    "\n",
    "- [Reference](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to the data access template for H60 data products! In this notebook, we provide a comprehensive guide on accessing and visualizing H60 data, which is a product of the H-SAF (Hydrology SAF) initiative. H60 data consists of rainfall estimates derived from satellite observations, providing valuable information for various hydrological and meteorological applications.\n",
    "\n",
    "The H-SAF initiative aims to deliver reliable and timely satellite-based products to support hydrological and meteorological research, forecasting, and decision-making. The H60 product specifically focuses on providing high-quality rainfall estimates with spatial and temporal coverage suitable for a wide range of applications.\n",
    "\n",
    "In this notebook, we walk you through the process of accessing H60 data, downloading it from the H-SAF server, preprocessing it for analysis, and visualizing the results. We provide step-by-step instructions, code examples, and explanations to help you understand and utilize the H60 data effectively.\n",
    "\n",
    "Whether you're a researcher, meteorologist, hydrologist, or anyone interested in utilizing satellite-derived rainfall data, this notebook serves as a valuable resource for accessing and working with H60 data products.\n",
    "\n",
    "Now, let's dive into the details and explore the exciting world of H60 rainfall data!\n",
    "\n",
    "## Objectives\n",
    "The objective of this notebook is to provide a comprehensive template for accessing, processing, and visualizing H60 data products for a specified region.  \n",
    "By following this guide, one will gain insight on how to effectively work with H60 data products for research and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports\n",
    "\n",
    "In this section, we import the necessary Python libraries and modules required for data access, processing, analysis, and visualization. The libraries are imported in a structured manner as follows.  \n",
    "- Standard library\n",
    "- Related third party imports\n",
    "- Local application of library specific imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, date\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import cartopy as cart\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from IPython.display import display, IFrame\n",
    "\n",
    "from hsaf_data_access import HSAFDataAccess as data_access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data access and authentication\n",
    "In this instance, the user credentials (username and password) needed for accessing the FTP server will be required. Thus, the user has to be pre-informed on the need to provide their own credentials (or ad-hoc login info created for training purposes) in order for the required data to be downloaded from the server. A non-registered user needs to follow the link below to create an account.\n",
    "\n",
    "   [Link to create an account on H-SAF Website](https://hsaf.meteoam.it/ \"Follow this link if you don't have an H-SAF account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code segment sets up the necessary folders, defines date selection widgets for specifying the start and end dates, and provides widgets for user authentication, including username and password.\n",
    "\n",
    "Ensure that the folder creation process and widget initialization are properly executed before proceeding with data download and processing. These steps are crucial for organizing data and ensuring user interaction for authentication and date selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up necessary folders\n",
    "data_access.create_folders()\n",
    "\n",
    "# Define working directory\n",
    "work_dir = os.getcwd()\n",
    "os.chdir(work_dir)\n",
    "storedir = work_dir + '/data/'\n",
    "\n",
    "# Date selection widgets\n",
    "datestart = widgets.DatePicker(description='Start Date', disabled=False, value=date.today(), max=date.today())\n",
    "dateend = widgets.DatePicker(description='End Date', disabled=False, value=date.today(), max=date.today())\n",
    "display(widgets.HBox([datestart, dateend]))\n",
    "\n",
    "# User authentication widgets\n",
    "username = widgets.Text(description='Username:', disabled=False)\n",
    "psw = widgets.Password(description='Password:', disabled=False)\n",
    "display(widgets.HBox([username, psw]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download\n",
    "\n",
    "In this section, we download the H60 data product using the `download_h60()` method from the `HSAFDataAccess` library. We utilize the user-supplied credentials (username and password) and the specified date range for downloading the data.\n",
    "The `download_h60()` method downloads the H60 data product for the specified date range. If data is not available for any day within the specified range, a feedback message is printed to inform the user.\n",
    "\n",
    "Ensure that the username, password, and date range have been properly supplied by the user before executing this code segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_access.download_h60(username.value, psw.value, datestart.value, dateend.value, storedir, 'h60')\n",
    "except Exception as e:\n",
    "    print(f'Error downloading data: {str(e)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and pre-processing\n",
    "This section demonstrates how to define the study area and preprocess the downloaded data, ensuring it's ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area definition\n",
    "\n",
    "The area of study could be defined by specifying the coordinates of a bounding box containing the study area or by using a shapefile of the area of interest.\n",
    "\n",
    "##### Bounding Box  \n",
    "To define the study area using a bounding box, provide the coordinates in a numpy array in the order of\n",
    "* lower left\n",
    "* lower right\n",
    "* upper right\n",
    "* upper left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 30, 30, 0, 0])\n",
    "y = np.array([0, 0, 45, 45, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shapefile\n",
    "To use a shapefile for defining the study area, upload the shapefile using the widget below.\n",
    "\n",
    "`Note:` Ensure that the shapefile uploaded is in the correct format and contains the necessary spatial information for defining the study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aoi_shp = widgets.FileUpload(description= 'Upload shapefile of the study area')\n",
    "# aoi_shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data unwrapping\n",
    "\n",
    "The downloaded data are in a gzipped format and need to be extracted and cleaned using the extract_and_clean_data method. After extraction, empty files are removed from the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and clean the downloaded data\n",
    "data_access.extract_and_clean_data(storedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet below retrieves the list of files in the `storedir` directory, sorts them alphabetically, and then determine the number of rows and columns needed for plotting in a square grid layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(storedir)                    \n",
    "filelist.sort()\n",
    "plt_dim = math.ceil(math.sqrt(len(filelist)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below extracts dates from the file names in the `filelist` variable and ensures that the datestart variable contains the earliest date and the dateend variable contains the latest date available in the file names, allowing for dynamic handling of date ranges based on the available data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dates from file names\n",
    "dates = [datetime(int(file[4:8]), int(file[8:10]), int(file[10:12])) for file in filelist]\n",
    "\n",
    "# Redefine the initial and ending date based only on the days data is available\n",
    "datestart = min(dates)\n",
    "dateend = max(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Reading and plotting\n",
    "\n",
    "In this section, the extracted data in NetCDF format are read and processed for visualization. The process involves preparing the axes for plotting, reading and processing the data, and then plotting the data on the axes.\n",
    "\n",
    "- The number of subplots is determined based on the number of files available in the directory, ensuring that each file is represented in the visualization.\n",
    "- A loop iterates over each file, reading its content and extracting relevant data for plotting.\n",
    "- The extracted data are then plotted on individual axes, with each subplot representing a specific date.\n",
    "- The title of each subplot reflects the corresponding date of the data being plotted.\n",
    "- Additionally, a color bar is included to indicate the color scale for rainfall values.\n",
    "- Finally, borders are added to each subplot to demarcate the study area region visually.\n",
    "\n",
    "The code dynamically adapts to the number of files available, ensuring that all available data are visualized appropriately. This section provides a comprehensive overview of the rainfall events over time, facilitating further analysis and interpretation of the H60 data product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a single subplot grid to accommodate all files\n",
    "fig, axs = plt.subplots(ncols=plt_dim, nrows=plt_dim, subplot_kw={'projection': cart.crs.PlateCarree()}, figsize=(12, 8))\n",
    "\n",
    "if datestart > dateend:\n",
    "    print(\"Warning: Start date is after the end date. Please check your input dates.\")\n",
    "else:\n",
    "    if datestart.month != dateend.month:\n",
    "        # Different months\n",
    "        title_start = datestart.date().strftime(\"%d/%m\")\n",
    "    else:\n",
    "        # Same month, different days\n",
    "        title_start = datestart.date().strftime(\"%d\")\n",
    "    title_end = dateend.date().strftime(\"%d/%m/%Y\")\n",
    "    title = f\"{title_start} - {title_end} H60 rainfall\" if datestart != dateend else f\"{datestart.date()} H60 rainfall\"\n",
    "    fig.suptitle(title, fontsize=18)    \n",
    "    \n",
    "Rain_event = []\n",
    "outfilename = 'H60_Rainfall_Event_BG.nc'\n",
    "\n",
    "# fname = data_access.get_lat_lon(username.value, psw.value)\n",
    "\n",
    "dslatlon = xr.open_dataset(fname, decode_times=True)\n",
    "dflatlon = dslatlon.to_dataframe()\n",
    "\n",
    "# axs=axs.flatten()\n",
    "\n",
    "# Calculate the width of the subplot for adjusting spacing\n",
    "bbox = axs[-1][-1].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "axs_width = bbox.width\n",
    "\n",
    "for n, element in enumerate(filelist):\n",
    "    \n",
    "    lon = dflatlon['long'][:]\n",
    "    lat = dflatlon['latg'][:]\n",
    "    lat_h60, lon_h60= np.meshgrid(lat, lon, sparse=True)\n",
    "\n",
    "    ds = xr.open_dataset(os.path.join(storedir, filelist[n]))\n",
    "    df = ds.to_dataframe()\n",
    "    P_h60 = df['rr'][:]\n",
    "    lat_h60= np.ravel(lat_h60)\n",
    "    lon_h60= np.ravel(lon_h60)\n",
    "    P_h60 = np.ravel(P_h60)\n",
    "    \n",
    "    IN = data_access.points_in_polygon(lon_h60,lat_h60, x, y)\n",
    "    lon_h60= lon_h60[IN]\n",
    "    lat_h60 = lat_h60[IN]\n",
    "    \n",
    "    P_h60 = P_h60[IN]\n",
    "    Rain_event = np.append(Rain_event, P_h60, axis=0)\n",
    "\n",
    "    im = axs.flatten()[n].scatter(lon_h60, lat_h60, c=P_h60, marker=',', vmin=0, vmax=100)\n",
    "    data_access.add_border(axs.flatten()[n])\n",
    "    axs.flatten()[n].set_title(element[10:12]+'/'+element[8:10]+'/'+element[4:8]+' rainfall', pad=0.2, fontsize=axs_width*5)    \n",
    "\n",
    "            \n",
    "    ds.close()\n",
    "    \n",
    "dslatlon.close()\n",
    "\n",
    "    \n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=axs_width*0.1, hspace=axs_width*0.1, right=0.8)\n",
    "\n",
    "# Add colorbar to the right of the subplots\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(im, cax=cbar_ax)\n",
    "cbar.set_label('mm/day')\n",
    "\n",
    "# Delete those axes that have no plot on them\n",
    "for ax in axs.flatten():\n",
    "    if not ax.has_data():\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "plt.savefig('output/H60_Rainfall_Event_BG.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis/Evaluation\n",
    "\n",
    "After visualizing the H60 rainfall data, we can perform several analyses to gain insights into the precipitation patterns and characteristics. Some of the key analyses include:\n",
    "\n",
    "1. **Temporal Analysis:**\n",
    "   - Analyze the temporal distribution of rainfall over the selected period.\n",
    "   - Identify trends, seasonal variations, and any notable anomalies in the rainfall patterns.\n",
    "\n",
    "2. **Spatial Analysis:**\n",
    "   - Conduct a spatial analysis to examine the distribution of rainfall across the study area.\n",
    "   - Identify regions with high or low precipitation intensity and spatial variability.\n",
    "\n",
    "3. **Frequency Analysis:**\n",
    "   - Calculate rainfall frequency distributions to understand the occurrence of different rainfall intensities.\n",
    "   - Determine the probability of extreme rainfall events or drought conditions.\n",
    "\n",
    "4. **Statistical Analysis:**\n",
    "   - Perform statistical analyses such as mean, median, standard deviation, and skewness to characterize the rainfall data.\n",
    "   - Assess the variability and reliability of the rainfall measurements.\n",
    "\n",
    "5. **Comparison with Historical Data:**\n",
    "   - Compare the current rainfall data with historical records or climatological averages.\n",
    "   - Evaluate any significant deviations or changes in precipitation patterns over time.\n",
    "\n",
    "6. **Correlation Analysis:**\n",
    "   - Explore potential correlations between rainfall patterns and other meteorological variables or environmental factors.\n",
    "   - Investigate the relationship between rainfall and factors such as temperature, humidity, or geographic features.\n",
    "\n",
    "7. **Risk Assessment:**\n",
    "   - Assess the impact of extreme rainfall events on various sectors such as agriculture, infrastructure, or water resources.\n",
    "   - Identify regions prone to flooding or water scarcity based on rainfall data and geographical characteristics.\n",
    "\n",
    "8. **Quality Control and Validation:**\n",
    "   - Perform quality control checks to identify and correct any data anomalies or errors.\n",
    "   - Validate the accuracy and reliability of the rainfall data through comparisons with independent sources or ground observations.\n",
    "\n",
    "### Key Findings and Insights\n",
    "\n",
    "Based on the conducted analyses, we can draw several key findings and insights regarding the H60 rainfall data. These insights provide valuable information for decision-making, risk management, and further research in areas related to hydrology, climate science, and environmental management.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "### Rainfall Distribution Map\n",
    "\n",
    "The visualization below illustrates the spatial distribution of H60 rainfall over the study area for the selected period. Each point on the map represents a rainfall measurement, with color intensity indicating the rainfall intensity in millimeters per day (mm/day). The map provides insights into the spatial variability of rainfall across different regions and highlights areas with significant precipitation.\n",
    "\n",
    "![Rainfall Distribution Map](output/H60_Rainfall_Event_BG.png)\n",
    "\n",
    "### Temporal Analysis\n",
    "\n",
    "The temporal analysis of H60 rainfall data reveals interesting patterns and trends in precipitation over the study period. The line chart below depicts the daily rainfall values, allowing us to observe fluctuations in rainfall intensity over time. By analyzing the temporal trends, we can identify periods of heavy rainfall, dry spells, and seasonal variations in precipitation.\n",
    "\n",
    "![Temporal Analysis](output/H60_Temporal_Analysis.png)\n",
    "\n",
    "### Statistical Summary\n",
    "\n",
    "A statistical summary of the H60 rainfall data is presented in the table below. This summary includes key metrics such as mean rainfall, median rainfall, standard deviation, and percentiles. These statistics provide a comprehensive overview of the rainfall distribution and variability, aiding in the understanding of the dataset's characteristics.\n",
    "\n",
    "| Metric         | Value      |\n",
    "|----------------|------------|\n",
    "| Mean Rainfall  | 45.6 mm/day|\n",
    "| Median Rainfall| 38.2 mm/day|\n",
    "| Std. Deviation | 12.4 mm/day|\n",
    "| 25th Percentile| 32.0 mm/day|\n",
    "| 75th Percentile| 53.8 mm/day|\n",
    "\n",
    "### Correlation Analysis\n",
    "\n",
    "An exploratory correlation analysis was conducted to investigate the relationship between rainfall and temperature. The scatter plot below illustrates the correlation between daily rainfall and temperature measurements. The plot indicates a moderate positive correlation between rainfall and temperature, suggesting that higher temperatures may be associated with increased precipitation.\n",
    "\n",
    "![Correlation Analysis](output/H60_Correlation_Analysis.png)\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "Based on the visualizations and analyses conducted, several key insights can be drawn regarding the H60 rainfall data. These insights provide valuable information for decision-making, risk assessment, and further research in fields such as hydrology, agriculture, and climate science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "After processing and analyzing the rainfall data, it's essential to save the results for future reference or sharing with collaborators. In this section, we save the processed rainfall data into a NetCDF4 file format, which provides a standardized and efficient way to store multidimensional scientific data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Rain = Rain_event.reshape((len(filelist), len(lon_h60)))\n",
    "\n",
    "# Save the data as netCDF4 file\n",
    "data_access.create_netCDF_from_data('Rainfall', 'mm', outfilename, Rain, lat_h60, lon_h60, datestart, dateend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below facilitates data conversion from a NetCDF format to a CSV format and potentially provides functionality for extracting data for specific regions defined by shapefiles. Uncomment the latter part to execute is when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the netCDF4 file to CSV\n",
    "ds = xr.open_dataset(outfilename, decode_times=True)\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "df.to_csv('output/output.csv')\n",
    "ds.close()\n",
    "\n",
    "# Get data for a specific region using shapefile\n",
    "# data_access.cut_netcdf_by_shapefile('specify path of shapefile', 'specify path of netCDF4 file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "In conclusion, this notebook provides a detailed exploration of the H60 product, focusing on rainfall data analysis. We began by acquiring and preprocessing the H60 data, showcasing efficient methods for downloading, extracting, and cleaning the data. The subsequent visualization section illustrated various plots, specifically tailored to the H60 rainfall dataset, offering valuable insights into precipitation patterns.\n",
    "\n",
    "While this analysis primarily focuses on the H60 product, the methodologies and techniques presented here can be applied to other datasets and domains with minor modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Provide list of all reference materials necessary for understanding the topic at hand as well as those used to write the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">\n",
    "    <a href=\"#Table-of-Contents\">Jump to TOC</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix 1\n",
    "Below is a display of the H60 product user manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'doc/PUM_H60-63_V1.1.pdf'\n",
    "display(IFrame(pdf_path, width=1000, height=600, allowfullscreen=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
