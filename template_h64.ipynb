{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images.png\" width=\"100%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>TOPIC FOR THE TEMPLATE</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisite and data sources\n",
    "\n",
    "Here define the prerequisites for the notrbooks. See the guideline for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "Define the table of contents and update whenever new content is added to the page.\n",
    "\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "\n",
    "- [Objectives](#Objectives)\n",
    "\n",
    "- [Library imports](#Library-imports)\n",
    "\n",
    "- [Access and authentication](#Data-access-and-authentication)\n",
    "\n",
    "- [Data download](#Data-download)\n",
    "\n",
    "- [Data processing](#Data-reading-and-pre\\-processing-such-as-filter\\,-area-definition-and-data-sampling)\n",
    "\n",
    "- [Data analysis](#Data-analysis/evaluation-and-plotting)\n",
    "\n",
    "- [Results visualisation](#Results-visualisation)\n",
    "\n",
    "- [Save](#Save)\n",
    "\n",
    "- [Conclusion](#Conclusion)\n",
    "\n",
    "- [Reference](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Provide the introduction to the notebook here.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Define the objectives of the notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports\n",
    "\n",
    "As a reminder, the libraries are to be imported in the order of \n",
    "\n",
    "- Standard library\n",
    "- Related third party imports\n",
    "- Local application of library specific imports\n",
    "\n",
    "Remember to leave a space between each library grouping for organisational purposes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta, datetime, date\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import cartopy as cart\n",
    "import ipywidgets as widgets\n",
    "import math\n",
    "import xarray as xr\n",
    "from netCDF4 import num2date\n",
    "\n",
    "from hsaf_data_access import HSAFDataAccess as data_access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To carry out the exercise, we need to create auxiliary folders by name data and output where the downloaded data and the results of our processing will be stored respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an auxilliary code\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "else:\n",
    "    for f in os.listdir('data'):\n",
    "        os.remove(os.path.join('data', f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data access and authentication\n",
    "In this instance, the user credentials (username and password) needed for accessing the FTP server will be required. Thus, the user has to be pre-informed on the need to provide their own credentials (or ad-hoc login info created for training purposes) in order for the required data to be downloaded from the server. A non-registered user needs to follow the link below to create an account.\n",
    "\n",
    "   [Link to create an account on H-SAF Website](https://hsaf.meteoam.it/ \"Follow this link if you don't have an H-SAF account\")\n",
    "\n",
    "The user credentials are to be entered in a widget available by running the code cell below.  \n",
    "In addition, a date picker tool is available for specifying the period in which the analysis is to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "os.chdir(work_dir)\n",
    "storedir = work_dir + '/data/'\n",
    "\n",
    "datestart = widgets.DatePicker(description='Start Date', disabled=False, value = date.today(), max = date.today())\n",
    "dateend = widgets.DatePicker(description='End Date', disabled=False, value = date.today(), max = date.today())\n",
    "display(widgets.HBox([datestart, dateend]))\n",
    "\n",
    "\n",
    "username = widgets.Text(description='Username:', disabled=False)\n",
    "psw = widgets.Password(description='Password:', disabled=False)\n",
    "display(widgets.HBox([username, psw]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download\n",
    "The values of the username, password and date picker widgets will be supplied as argument for the download function. However, data will be downloaded for only the days in the date range in which data is available. For days in which data is not available, feedback message is printed to the end-user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_access.download_h64(username.value, psw.value, datestart.value, dateend.value, storedir, 'h64')\n",
    "except:\n",
    "    print('Incorrect parameters in the \\'Data access and authentication\\' section')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and pre-processing such as filter, area definition and data sampling\n",
    "\n",
    "The variables x and y in this section indicate the coordinates of the bounding box around defining the area of study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area definition\n",
    "Specify the bounding box of the study area in the numpy array in the order of \n",
    "* lower left\n",
    "* lower right\n",
    "* upper right\n",
    "* upper left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([20, 30, 30, 20, 20])\n",
    "y = np.array([35, 35, 45, 45, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data unwrapping\n",
    "The downloaded data are in a gz wrap and here we need to extract the content of the zip file in the data folder.  \n",
    "Also, we need to remove empty files after the extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_access.extract_gz_file(storedir)\n",
    "\n",
    "# Remove empty files\n",
    "for f, ff, in enumerate(os.listdir(storedir)):\n",
    "    if os.stat(ff).st_size == 0:\n",
    "        os.remove(ff)\n",
    "\n",
    "                            \n",
    "filelist = os.listdir(storedir)                    \n",
    "filelist.sort()\n",
    "plt_dim = math.ceil(math.sqrt(len(filelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the initial and ending date based only on the days data is available\n",
    "datestart = datetime(int(filelist[0][4:8]), int(filelist[0][8:10]), int(filelist[0][10:12]))\n",
    "dateend = datetime(int(filelist[-1][4:8]), int(filelist[-1][8:10]), int(filelist[-1][10:12]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Reading and plotting\n",
    "The extracted data are in a netCDF4 format and we need to read them here.\n",
    "We start by preparing the axes on which the plots are going to be made, read and process the data and then plot on the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of subplots according to the number of files in the directory\n",
    "if len(filelist) > 1:\n",
    "    fig, axs = plt.subplots(ncols=plt_dim, nrows=plt_dim, subplot_kw={'projection': cart.crs.PlateCarree()})\n",
    "    axs = axs.ravel()  \n",
    "    \n",
    "else:\n",
    "    fig, axs = plt.subplots(ncols=1, nrows=1, squeeze=False, subplot_kw={'projection': cart.crs.PlateCarree()})\n",
    "    \n",
    "# The title of the figure based on the difference between the start and end dates\n",
    "if dateend > datestart:\n",
    "    if dateend.year > datestart.year:\n",
    "        fig.suptitle(datestart.date().strftime(\"%d/%m/%Y\") + ' - ' + dateend.date().strftime(\"%d/%m/%Y\") + \n",
    "                     ' H60 rainfall', fontsize=18)\n",
    "    elif dateend.month > datestart.month:\n",
    "        fig.suptitle(datestart.date().strftime(\"%d/%m\") + ' - ' + dateend.date().strftime(\"%d/%m/%Y\") + \n",
    "                     ' H60 rainfall', fontsize=18)\n",
    "    else:\n",
    "        fig.suptitle(datestart.date().strftime(\"%d\") + ' - ' + dateend.date().strftime(\"%d/%m/%Y\") +\n",
    "                      ' H60 rainfall', fontsize=18)\n",
    "else:\n",
    "    fig.suptitle(datestart.date().strftime(\"%d/%m/%Y\") + ' H60 rainfall',\n",
    "                  fontsize=18)\n",
    "    \n",
    "axs=axs.flatten()\n",
    "Rain_event = []\n",
    "outfilename = 'H64_Rainfall_Event_BG.nc'\n",
    "\n",
    "for n, element in enumerate(filelist):\n",
    "    ds = nc.Dataset(element, mmap=False)\n",
    "    lon = ds['lon'][:]\n",
    "    lat = ds['lat'][:]\n",
    "    P_h64 = ds['acc_rr'][:]\n",
    "    lat_h64, lon_h64 = np.meshgrid(lat, lon)\n",
    "    lat_h64 = np.ravel(lat_h64)\n",
    "    lon_h64 = np.ravel(lon_h64)\n",
    "    IN = data_access.in_polygon(lon_h64, lat_h64, x, y)\n",
    "    lon_h64 = lon_h64[IN]\n",
    "    lat_h64 = lat_h64[IN]\n",
    "    P_h64 = np.transpose(P_h64)\n",
    "    P_h64 = np.ma.getdata(P_h64)\n",
    "    P_h64 = np.where(P_h64 < 1, np.NaN, P_h64)\n",
    "    P_h64 = np.ravel(P_h64)\n",
    "    P_h64 = P_h64[IN]\n",
    "    Rain_event = np.append(Rain_event, P_h64, axis=0)\n",
    "    if len(filelist) == 1:\n",
    "        im = axs[n].scatter(lon_h64, lat_h64, c=P_h64, marker=',', vmin=0, vmax=100)\n",
    "        axs[n].set_title(element[10:12]+'/'+element[8:10]+'/'+element[4:8]+' rainfall', y=-0.1)\n",
    "        cbar = fig.colorbar(im, ax=axs, aspect=30, shrink=0.70)\n",
    "        cbar.ax.set_xlabel('mm/day', loc='left')\n",
    "    else:\n",
    "        bbox = axs[n].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "        axs_width = bbox.width\n",
    "        im = axs[n].scatter(lon_h64, lat_h64, c=P_h64, marker=',', vmin=0, vmax=100)\n",
    "        axs[n].set_title(element[10:12]+'/'+element[8:10]+'/'+element[4:8], pad=0.2, fontsize=axs_width*10)\n",
    "        plt.subplots_adjust(wspace=axs_width, hspace=axs_width)\n",
    "         \n",
    "        if n == len(filelist)-1:\n",
    "            cbar = fig.colorbar(im, ax=axs)\n",
    "            cbar.set_label('mm/day', loc='center')\n",
    "    data_access.add_border(axs[n])\n",
    "    \n",
    "    ds.close()\n",
    "\n",
    "# Delete those axes that have no plot on them\n",
    "for ax in axs.flatten():\n",
    "    if not ax.has_data():\n",
    "        fig.delaxes(ax)\n",
    "\n",
    "os.chdir(work_dir)\n",
    "plt.savefig('output/H64_Rainfall_Event_BG.png', dpi=300)\n",
    "plt.close()\n",
    "Rain = Rain_event.reshape((len(filelist), len(lon_h64)))\n",
    "\n",
    "plt.figure(1)\n",
    "Rain_plot = np.nansum(Rain, 0)\n",
    "Rain_plot = np.where(Rain_plot < 1, np.NaN, Rain_plot)\n",
    "\n",
    "bckg = plt.axes(projection=cart.crs.PlateCarree())\n",
    "data_access.add_border(bckg)\n",
    "\n",
    "im2 = plt.scatter(lon_h64, lat_h64,c=Rain_plot, marker=',', vmin=0, vmax=200)\n",
    "plt.title('Total event rainfall', fontsize=16)\n",
    "cbar2 = plt.colorbar(shrink=0.66)\n",
    "cbar2.set_label('mm')\n",
    "plt.savefig('output/H64_Total_Rainfall_BG.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data analysis/evaluation\n",
    "Given that the plot has been made, analysis on it needs to be made. Other explanation for the variation of the variable are also made in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results visualisation\n",
    "Show the plot in this section. Please note that a square grid is used for making the plots and axes, which do not have plots on them, are deleted. This is due to the dynamic nature of the subplot dimensions, which depend on the number of days analysis is being made. \n",
    "\n",
    "![alt_text](output/H64_Rainfall_Event_BG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the data as netCDF4 file\n",
    "data_access.to_netCDF('Rainfall', 'mm', outfilename, Rain, lat_h64, lon_h64, datestart, dateend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the netCDF4 file to CSV\n",
    "ds = xr.open_dataset(outfilename, decode_times=True)\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "df.to_csv('output/output.csv')\n",
    "ds.close()\n",
    "\n",
    "# Get data for a specific region using shapefile\n",
    "# data_access.cut_by_shp('specify path of shapefile', 'specify path of netCDF4 file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "Give a short concluding statement to the work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "Provide list of all reference materials necessary for understanding the topic at hand as well as those used to write the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump to TOC](#Table-of-Contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
